{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adkcsSpk6K5Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Data Generation Function for each person\n",
        "def generate_eye_tracking_data(num_samples):\n",
        "    # Generate synthetic eye-tracking metrics\n",
        "    fixation_duration = np.random.uniform(150, 600, num_samples)  # in milliseconds\n",
        "    saccade_amplitude = np.random.uniform(1, 40, num_samples)     # in degrees\n",
        "    pupil_dilation = np.random.uniform(2, 8, num_samples)         # in millimeters\n",
        "    blink_rate = np.random.uniform(10, 20, num_samples)           # blinks per minute\n",
        "    gaze_x = np.random.uniform(0, 1920, num_samples)              # screen resolution width\n",
        "    gaze_y = np.random.uniform(0, 1080, num_samples)              # screen resolution height\n",
        "\n",
        "    # Combine features into a single dataset\n",
        "    X = np.column_stack((fixation_duration, saccade_amplitude, pupil_dilation, blink_rate, gaze_x, gaze_y))\n",
        "\n",
        "    # Generate binary labels (0: Healthy, 1: Early-stage Alzheimer's)\n",
        "    # Higher fixation duration, pupil dilation, and blink rate may indicate Alzheimer's.\n",
        "    y = (fixation_duration + pupil_dilation + blink_rate) > (fixation_duration.mean() + pupil_dilation.mean() + blink_rate.mean())\n",
        "    y = y.astype(int)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Function to generate and save data for multiple individuals\n",
        "def generate_and_save_data(num_individuals, num_samples_per_person, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    all_data = []\n",
        "\n",
        "    for i in range(num_individuals):\n",
        "        X, y = generate_eye_tracking_data(num_samples_per_person)\n",
        "        person_data = np.column_stack((np.full(num_samples_per_person, i), X, y))\n",
        "        all_data.append(person_data)\n",
        "\n",
        "        # Save each person's data to a CSV file\n",
        "        df = pd.DataFrame(person_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "        df.to_csv(os.path.join(output_dir, f'person_{i}.csv'), index=False)\n",
        "\n",
        "    # Combine all data into a single dataframe\n",
        "    all_data = np.vstack(all_data)\n",
        "    df_all = pd.DataFrame(all_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "    df_all.to_csv(os.path.join(output_dir, 'all_data.csv'), index=False)\n",
        "\n",
        "# Generate and save data\n",
        "output_dir = 'eye_tracking_data'\n",
        "num_individuals = 400  # Number of individuals\n",
        "num_samples_per_person = 4  # Number of samples per individual\n",
        "\n",
        "generate_and_save_data(num_individuals, num_samples_per_person, output_dir)\n",
        "\n",
        "# Load the data from CSV\n",
        "df = pd.read_csv(os.path.join(output_dir, 'all_data.csv'))\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df[['FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY']].values\n",
        "y = df['Label'].values\n",
        "\n",
        "# Reshape X for LSTM input [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Split the data into 70% train, 15% validation, 15% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the Bi-LSTM Model with Attention Mechanism\n",
        "def build_bilstm_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Bi-LSTM Layer\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = layers.Attention()([x, x])\n",
        "\n",
        "    # Flatten the output of the attention layer\n",
        "    x = layers.Flatten()(attention)\n",
        "\n",
        "    # Dense Layers\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and Train the Model\n",
        "model = build_bilstm_attention_model((X_train.shape[1], X_train.shape[2]))\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Plot the Training and Validation Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the Training and Validation Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Data Generation Function\n",
        "def generate_eye_tracking_data(num_samples, category):\n",
        "    # Generate synthetic eye-tracking metrics with different distributions based on the category\n",
        "    if category == 'healthy':\n",
        "        fixation_duration = np.random.uniform(150, 300, num_samples)  # Healthy range\n",
        "        saccade_amplitude = np.random.uniform(20, 40, num_samples)    # Healthy range\n",
        "        pupil_dilation = np.random.uniform(2, 4, num_samples)         # Healthy range\n",
        "        blink_rate = np.random.uniform(10, 15, num_samples)           # Healthy range\n",
        "    elif category == 'early_alz':\n",
        "        fixation_duration = np.random.uniform(300, 450, num_samples)  # Early-stage range\n",
        "        saccade_amplitude = np.random.uniform(10, 20, num_samples)    # Early-stage range\n",
        "        pupil_dilation = np.random.uniform(4, 6, num_samples)         # Early-stage range\n",
        "        blink_rate = np.random.uniform(15, 20, num_samples)           # Early-stage range\n",
        "    else:  # category == 'alz'\n",
        "        fixation_duration = np.random.uniform(450, 600, num_samples)  # Alzheimer's range\n",
        "        saccade_amplitude = np.random.uniform(1, 10, num_samples)     # Alzheimer's range\n",
        "        pupil_dilation = np.random.uniform(6, 8, num_samples)         # Alzheimer's range\n",
        "        blink_rate = np.random.uniform(20, 25, num_samples)           # Alzheimer's range\n",
        "\n",
        "    gaze_x = np.random.uniform(0, 1920, num_samples)              # screen resolution width\n",
        "    gaze_y = np.random.uniform(0, 1080, num_samples)              # screen resolution height\n",
        "\n",
        "    # Combine features into a single dataset\n",
        "    X = np.column_stack((fixation_duration, saccade_amplitude, pupil_dilation, blink_rate, gaze_x, gaze_y))\n",
        "\n",
        "    # Generate labels (0: Healthy, 1: Early-stage Alzheimer's, 2: Alzheimer's)\n",
        "    y = 0 if category == 'healthy' else (1 if category == 'early_alz' else 2)\n",
        "\n",
        "    return X, np.full(num_samples, y)\n",
        "\n",
        "# Function to generate and save data for multiple individuals\n",
        "def generate_and_save_data(num_individuals, num_samples_per_person, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    all_data = []\n",
        "\n",
        "    for i in range(num_individuals):\n",
        "        if i < 200:\n",
        "            category = 'healthy'\n",
        "        elif i < 300:\n",
        "            category = 'early_alz'\n",
        "        else:\n",
        "            category = 'alz'\n",
        "\n",
        "        X, y = generate_eye_tracking_data(num_samples_per_person, category)\n",
        "        person_data = np.column_stack((np.full(num_samples_per_person, i), X, y))\n",
        "        all_data.append(person_data)\n",
        "\n",
        "        # Save each person's data to a CSV file\n",
        "        df = pd.DataFrame(person_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "        df.to_csv(os.path.join(output_dir, f'person_{i}.csv'), index=False)\n",
        "\n",
        "    # Combine all data into a single dataframe\n",
        "    all_data = np.vstack(all_data)\n",
        "    df_all = pd.DataFrame(all_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "    df_all.to_csv(os.path.join(output_dir, 'all_data.csv'), index=False)\n",
        "\n",
        "# Generate and save data\n",
        "output_dir = 'eye_tracking_data'\n",
        "num_individuals = 400  # Number of individuals\n",
        "num_samples_per_person = 4  # Number of samples per individual\n",
        "\n",
        "generate_and_save_data(num_individuals, num_samples_per_person, output_dir)\n",
        "\n",
        "# Load the data from CSV\n",
        "df = pd.read_csv(os.path.join(output_dir, 'all_data.csv'))\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df[['FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY']].values\n",
        "y = df['Label'].values\n",
        "\n",
        "# Reshape X for LSTM input [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Split the data into 70% train, 15% validation, 15% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the Bi-LSTM Model with Attention Mechanism\n",
        "def build_bilstm_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Bi-LSTM Layer\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = layers.Attention()([x, x])\n",
        "\n",
        "    # Flatten the output of the attention layer\n",
        "    x = layers.Flatten()(attention)\n",
        "\n",
        "    # Dense Layers\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)  # Multi-class classification for 3 classes\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and Train the Model\n",
        "model = build_bilstm_attention_model((X_train.shape[1], X_train.shape[2]))\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Save model predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "df_predictions = pd.DataFrame(predictions, columns=['Healthy_Prob', 'Early_Alz_Prob', 'Alz_Prob'])\n",
        "df_predictions['True_Label'] = y_test\n",
        "df_predictions.to_csv(os.path.join(output_dir, 'test_predictions.csv'), index=False)\n",
        "\n",
        "# Plot the Training and Validation Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the Training and Validation Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Example evaluation and plotting for 3 different individuals\n",
        "def plot_individual_data(person_id, df):\n",
        "    person_df = df[df['PersonID'] == person_id]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(person_df['FixationDuration'], label='Fixation Duration')\n",
        "    plt.plot(person_df['SaccadeAmplitude'], label='Saccade Amplitude')\n",
        "    plt.plot(person_df['PupilDilation'], label='Pupil Dilation')\n",
        "    plt.plot(person_df['BlinkRate'], label='Blink Rate')\n",
        "    plt.title(f'Person {person_id} Data Over 4 Sessions')\n",
        "    plt.xlabel('Session')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Plot data for an individual with Alzheimer's\n",
        "plot_individual_data(300, df)\n",
        "\n",
        "# Plot data for an individual with early-stage Alzheimer's\n",
        "plot_individual_data(250, df)\n",
        "\n",
        "# Plot data for a healthy individual\n",
        "plot_individual_data(100, df)\n"
      ],
      "metadata": {
        "id": "kTHk_9y0-l6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Data Generation Function\n",
        "def generate_eye_tracking_data(num_samples, category):\n",
        "    # Generate synthetic eye-tracking metrics with different distributions based on the category\n",
        "    if category == 'healthy':\n",
        "        fixation_duration = np.random.uniform(150, 300, num_samples)  # Healthy range\n",
        "        saccade_amplitude = np.random.uniform(20, 40, num_samples)    # Healthy range\n",
        "        pupil_dilation = np.random.uniform(2, 4, num_samples)         # Healthy range\n",
        "        blink_rate = np.random.uniform(10, 15, num_samples)           # Healthy range\n",
        "    elif category == 'early_alz':\n",
        "        fixation_duration = np.random.uniform(300, 450, num_samples)  # Early-stage range\n",
        "        saccade_amplitude = np.random.uniform(10, 20, num_samples)    # Early-stage range\n",
        "        pupil_dilation = np.random.uniform(4, 6, num_samples)         # Early-stage range\n",
        "        blink_rate = np.random.uniform(15, 20, num_samples)           # Early-stage range\n",
        "    else:  # category == 'alz'\n",
        "        fixation_duration = np.random.uniform(450, 600, num_samples)  # Alzheimer's range\n",
        "        saccade_amplitude = np.random.uniform(1, 10, num_samples)     # Alzheimer's range\n",
        "        pupil_dilation = np.random.uniform(6, 8, num_samples)         # Alzheimer's range\n",
        "        blink_rate = np.random.uniform(20, 25, num_samples)           # Alzheimer's range\n",
        "\n",
        "    gaze_x = np.random.uniform(0, 1920, num_samples)              # screen resolution width\n",
        "    gaze_y = np.random.uniform(0, 1080, num_samples)              # screen resolution height\n",
        "\n",
        "    # Combine features into a single dataset\n",
        "    X = np.column_stack((fixation_duration, saccade_amplitude, pupil_dilation, blink_rate, gaze_x, gaze_y))\n",
        "\n",
        "    # Generate labels (0: Healthy, 1: Early-stage Alzheimer's, 2: Alzheimer's)\n",
        "    y = 0 if category == 'healthy' else (1 if category == 'early_alz' else 2)\n",
        "\n",
        "    return X, np.full(num_samples, y)\n",
        "\n",
        "# Function to generate and save data for multiple individuals\n",
        "def generate_and_save_data(num_individuals, num_samples_per_person, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    all_data = []\n",
        "\n",
        "    for i in range(num_individuals):\n",
        "        if i < 200:\n",
        "            category = 'healthy'\n",
        "        elif i < 300:\n",
        "            category = 'early_alz'\n",
        "        else:\n",
        "            category = 'alz'\n",
        "\n",
        "        X, y = generate_eye_tracking_data(num_samples_per_person, category)\n",
        "        person_data = np.column_stack((np.full(num_samples_per_person, i), X, y))\n",
        "        all_data.append(person_data)\n",
        "\n",
        "        # Save each person's data to a CSV file\n",
        "        df = pd.DataFrame(person_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "        df.to_csv(os.path.join(output_dir, f'person_{i}.csv'), index=False)\n",
        "\n",
        "    # Combine all data into a single dataframe\n",
        "    all_data = np.vstack(all_data)\n",
        "    df_all = pd.DataFrame(all_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "    df_all.to_csv(os.path.join(output_dir, 'all_data.csv'), index=False)\n",
        "\n",
        "# Generate and save data\n",
        "output_dir = 'eye_tracking_data'\n",
        "num_individuals = 400  # Number of individuals\n",
        "num_samples_per_person = 4  # Number of samples per individual\n",
        "\n",
        "generate_and_save_data(num_individuals, num_samples_per_person, output_dir)\n",
        "\n",
        "# Load the data from CSV\n",
        "df = pd.read_csv(os.path.join(output_dir, 'all_data.csv'))\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df[['FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY']].values\n",
        "y = df['Label'].values\n",
        "\n",
        "# Reshape X for LSTM input [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Split the data into 70% train, 15% validation, 15% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the Bi-LSTM Model with Attention Mechanism\n",
        "def build_bilstm_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Bi-LSTM Layer\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = layers.Attention()([x, x])\n",
        "\n",
        "    # Flatten the output of the attention layer\n",
        "    x = layers.Flatten()(attention)\n",
        "\n",
        "    # Dense Layers\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)  # Multi-class classification for 3 classes\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and Train the Model\n",
        "model = build_bilstm_attention_model((X_train.shape[1], X_train.shape[2]))\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Save model predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "df_predictions = pd.DataFrame(predictions, columns=['Healthy_Prob', 'Early_Alz_Prob', 'Alz_Prob'])\n",
        "df_predictions['True_Label'] = y_test\n",
        "df_predictions.to_csv(os.path.join(output_dir, 'test_predictions.csv'), index=False)\n",
        "\n",
        "# Select three random individuals from the test set for detailed analysis\n",
        "np.random.seed(42)\n",
        "random_indices = np.random.choice(df['PersonID'].unique(), 3, replace=False)\n",
        "\n",
        "# Function to plot and analyze individual data\n",
        "def analyze_individual(person_id, df, predictions, model):\n",
        "    person_df = df[df['PersonID'] == person_id]\n",
        "    true_label = int(person_df['Label'].iloc[0])  # Ensure true_label is an integer\n",
        "\n",
        "    # Predict the individual's class\n",
        "    X_person = person_df[['FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY']].values\n",
        "    X_person = X_person.reshape((X_person.shape[0], 1, X_person.shape[1]))\n",
        "    person_prediction = model.predict(X_person)\n",
        "    predicted_label = np.argmax(person_prediction.mean(axis=0))\n",
        "\n",
        "    # Determine the class\n",
        "    class_labels = ['Healthy', 'Early Alzheimer\\'s', 'Alzheimer\\'s']\n",
        "    true_class = class_labels[true_label]\n",
        "    predicted_class = class_labels[predicted_label]\n",
        "\n",
        "    # Generate plots\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    plt.plot(person_df['FixationDuration'], label='Fixation Duration', marker='o')\n",
        "    plt.plot(person_df['SaccadeAmplitude'], label='Saccade Amplitude', marker='s')\n",
        "    plt.plot(person_df['PupilDilation'], label='Pupil Dilation', marker='D')\n",
        "    plt.plot(person_df['BlinkRate'], label='Blink Rate', marker='^')\n",
        "    plt.title(f'Person {person_id} (True: {true_class}, Predicted: {predicted_class})')\n",
        "    plt.xlabel('Session')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print analysis report\n",
        "    print(f\"Person {person_id} Analysis Report\")\n",
        "    print(f\"True Label: {true_class}\")\n",
        "    print(f\"Predicted Label: {predicted_class}\")\n",
        "    print(f\"Prediction Probabilities: {person_prediction.mean(axis=0)}\")\n",
        "    print(\"-----------------------------------------------------------\\n\")\n",
        "\n",
        "\n",
        "# Analyze and report on the three selected individuals\n",
        "for person_id in random_indices:\n",
        "    analyze_individual(person_id, df, df_predictions, model)\n"
      ],
      "metadata": {
        "id": "W9GFRuAp_uq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Data Generation Function\n",
        "def generate_eye_tracking_data(num_samples, category):\n",
        "    # Generate synthetic eye-tracking metrics with different distributions based on the category\n",
        "    if category == 'healthy':\n",
        "        fixation_duration = np.random.uniform(150, 300, num_samples)  # Healthy range\n",
        "        saccade_amplitude = np.random.uniform(20, 40, num_samples)    # Healthy range\n",
        "        pupil_dilation = np.random.uniform(2, 4, num_samples)         # Healthy range\n",
        "        blink_rate = np.random.uniform(10, 15, num_samples)           # Healthy range\n",
        "    elif category == 'early_alz':\n",
        "        fixation_duration = np.random.uniform(300, 450, num_samples)  # Early-stage range\n",
        "        saccade_amplitude = np.random.uniform(10, 20, num_samples)    # Early-stage range\n",
        "        pupil_dilation = np.random.uniform(4, 6, num_samples)         # Early-stage range\n",
        "        blink_rate = np.random.uniform(15, 20, num_samples)           # Early-stage range\n",
        "    else:  # category == 'alz'\n",
        "        fixation_duration = np.random.uniform(450, 600, num_samples)  # Alzheimer's range\n",
        "        saccade_amplitude = np.random.uniform(1, 10, num_samples)     # Alzheimer's range\n",
        "        pupil_dilation = np.random.uniform(6, 8, num_samples)         # Alzheimer's range\n",
        "        blink_rate = np.random.uniform(20, 25, num_samples)           # Alzheimer's range\n",
        "\n",
        "    gaze_x = np.random.uniform(0, 1920, num_samples)              # screen resolution width\n",
        "    gaze_y = np.random.uniform(0, 1080, num_samples)              # screen resolution height\n",
        "\n",
        "    # Combine features into a single dataset\n",
        "    X = np.column_stack((fixation_duration, saccade_amplitude, pupil_dilation, blink_rate, gaze_x, gaze_y))\n",
        "\n",
        "    # Generate labels (0: Healthy, 1: Early-stage Alzheimer's, 2: Alzheimer's)\n",
        "    y = 0 if category == 'healthy' else (1 if category == 'early_alz' else 2)\n",
        "\n",
        "    return X, np.full(num_samples, y)\n",
        "\n",
        "# Function to generate and save data for multiple individuals\n",
        "def generate_and_save_data(num_individuals, num_samples_per_person, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    all_data = []\n",
        "\n",
        "    for i in range(num_individuals):\n",
        "        if i < 200:\n",
        "            category = 'healthy'\n",
        "        elif i < 300:\n",
        "            category = 'early_alz'\n",
        "        else:\n",
        "            category = 'alz'\n",
        "\n",
        "        X, y = generate_eye_tracking_data(num_samples_per_person, category)\n",
        "        person_data = np.column_stack((np.full(num_samples_per_person, i), X, y))\n",
        "        all_data.append(person_data)\n",
        "\n",
        "        # Save each person's data to a CSV file\n",
        "        df = pd.DataFrame(person_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "        df.to_csv(os.path.join(output_dir, f'person_{i}.csv'), index=False)\n",
        "\n",
        "    # Combine all data into a single dataframe\n",
        "    all_data = np.vstack(all_data)\n",
        "    df_all = pd.DataFrame(all_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "    df_all.to_csv(os.path.join(output_dir, 'all_data.csv'), index=False)\n",
        "\n",
        "# Generate and save data\n",
        "output_dir = 'eye_tracking_data'\n",
        "num_individuals = 400  # Number of individuals\n",
        "num_samples_per_person = 4  # Number of samples per individual\n",
        "\n",
        "generate_and_save_data(num_individuals, num_samples_per_person, output_dir)\n",
        "\n",
        "# Load the data from CSV\n",
        "df = pd.read_csv(os.path.join(output_dir, 'all_data.csv'))\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df[['FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY']].values\n",
        "y = df['Label'].values\n",
        "\n",
        "# Reshape X for LSTM input [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Split the data into 70% train, 15% validation, 15% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the Bi-LSTM Model with Attention Mechanism\n",
        "def build_bilstm_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Bi-LSTM Layer\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = layers.Attention()([x, x])\n",
        "\n",
        "    # Flatten the output of the attention layer\n",
        "    x = layers.Flatten()(attention)\n",
        "\n",
        "    # Dense Layers\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)  # Multi-class classification for 3 classes\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and Train the Model\n",
        "model = build_bilstm_attention_model((X_train.shape[1], X_train.shape[2]))\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Save model predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "df_predictions = pd.DataFrame(predictions, columns=['Healthy_Prob', 'Early_Alz_Prob', 'Alz_Prob'])\n",
        "df_predictions['True_Label'] = y_test\n",
        "df_predictions.to_csv(os.path.join(output_dir, 'test_predictions.csv'), index=False)\n",
        "\n",
        "# Generate data for three new individuals (not part of the original 400)\n",
        "new_individuals_data = []\n",
        "categories = ['healthy', 'early_alz', 'alz']\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    X_new, y_new = generate_eye_tracking_data(4, category)  # 4 samples per person\n",
        "    new_individuals_data.append((X_new, y_new, category))\n",
        "\n",
        "# Function to plot and analyze individual data\n",
        "def analyze_new_individual(X_new, y_new, category, model):\n",
        "    # Predict the individual's class\n",
        "    X_person = X_new.reshape((X_new.shape[0], 1, X_new.shape[1]))\n",
        "    person_prediction = model.predict(X_person)\n",
        "    predicted_label = np.argmax(person_prediction.mean(axis=0))\n",
        "\n",
        "    # Determine the class\n",
        "    class_labels = ['Healthy', 'Early Alzheimer\\'s', 'Alzheimer\\'s']\n",
        "    true_class = class_labels[y_new[0]]\n",
        "    predicted_class = class_labels[predicted_label]\n",
        "\n",
        "    # Generate plots\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    plt.plot(X_new[:, 0], label='Fixation Duration', marker='o')\n",
        "    plt.plot(X_new[:, 1], label='Saccade Amplitude', marker='s')\n",
        "    plt.plot(X_new[:, 2], label='Pupil Dilation', marker='D')\n",
        "    plt.plot(X_new[:, 3], label='Blink Rate', marker='^')\n",
        "    plt.title(f'New Individual ({category.capitalize()}) - Predicted: {predicted_class}')\n",
        "    plt.xlabel('Session')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print analysis report\n",
        "    print(f\"New Individual ({category.capitalize()}) Analysis Report\")\n",
        "    print(f\"True Label: {true_class}\")\n",
        "    print(f\"Predicted Label: {predicted_class}\")\n",
        "    print(f\"Prediction Probabilities: {person_prediction.mean(axis=0)}\")\n",
        "    print(\"-----------------------------------------------------------\\n\")\n",
        "\n",
        "# Analyze and report on the three new individuals\n",
        "for X_new, y_new, category in new_individuals_data:\n",
        "    analyze_new_individual(X_new, y_new, category, model)\n"
      ],
      "metadata": {
        "id": "3EWsM4tbAudO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Data Generation Function\n",
        "def generate_eye_tracking_data(num_samples, category):\n",
        "    # Generate synthetic eye-tracking metrics with different distributions based on the category\n",
        "    if category == 'healthy':\n",
        "        fixation_duration = np.random.uniform(150, 300, num_samples)  # Healthy range\n",
        "        saccade_amplitude = np.random.uniform(20, 40, num_samples)    # Healthy range\n",
        "        pupil_dilation = np.random.uniform(2, 4, num_samples)         # Healthy range\n",
        "        blink_rate = np.random.uniform(10, 15, num_samples)           # Healthy range\n",
        "    elif category == 'early_alz':\n",
        "        fixation_duration = np.random.uniform(300, 450, num_samples)  # Early-stage range\n",
        "        saccade_amplitude = np.random.uniform(10, 20, num_samples)    # Early-stage range\n",
        "        pupil_dilation = np.random.uniform(4, 6, num_samples)         # Early-stage range\n",
        "        blink_rate = np.random.uniform(15, 20, num_samples)           # Early-stage range\n",
        "    else:  # category == 'alz'\n",
        "        fixation_duration = np.random.uniform(450, 600, num_samples)  # Alzheimer's range\n",
        "        saccade_amplitude = np.random.uniform(1, 10, num_samples)     # Alzheimer's range\n",
        "        pupil_dilation = np.random.uniform(6, 8, num_samples)         # Alzheimer's range\n",
        "        blink_rate = np.random.uniform(20, 25, num_samples)           # Alzheimer's range\n",
        "\n",
        "    gaze_x = np.random.uniform(0, 1920, num_samples)              # screen resolution width\n",
        "    gaze_y = np.random.uniform(0, 1080, num_samples)              # screen resolution height\n",
        "\n",
        "    # Combine features into a single dataset\n",
        "    X = np.column_stack((fixation_duration, saccade_amplitude, pupil_dilation, blink_rate, gaze_x, gaze_y))\n",
        "\n",
        "    # Generate labels (0: Healthy, 1: Early-stage Alzheimer's, 2: Alzheimer's)\n",
        "    y = 0 if category == 'healthy' else (1 if category == 'early_alz' else 2)\n",
        "\n",
        "    return X, np.full(num_samples, y)\n",
        "\n",
        "# Function to generate and save data for multiple individuals\n",
        "def generate_and_save_data(num_individuals, num_samples_per_person, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    all_data = []\n",
        "\n",
        "    for i in range(num_individuals):\n",
        "        if i < 200:\n",
        "            category = 'healthy'\n",
        "        elif i < 300:\n",
        "            category = 'early_alz'\n",
        "        else:\n",
        "            category = 'alz'\n",
        "\n",
        "        X, y = generate_eye_tracking_data(num_samples_per_person, category)\n",
        "        person_data = np.column_stack((np.full(num_samples_per_person, i), X, y))\n",
        "        all_data.append(person_data)\n",
        "\n",
        "        # Save each person's data to a CSV file\n",
        "        df = pd.DataFrame(person_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "        df.to_csv(os.path.join(output_dir, f'person_{i}.csv'), index=False)\n",
        "\n",
        "    # Combine all data into a single dataframe\n",
        "    all_data = np.vstack(all_data)\n",
        "    df_all = pd.DataFrame(all_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "    df_all.to_csv(os.path.join(output_dir, 'all_data.csv'), index=False)\n",
        "\n",
        "# Generate and save data\n",
        "output_dir = 'eye_tracking_data'\n",
        "num_individuals = 400  # Number of individuals\n",
        "num_samples_per_person = 4  # Number of samples per individual\n",
        "\n",
        "generate_and_save_data(num_individuals, num_samples_per_person, output_dir)\n",
        "\n",
        "# Load the data from CSV\n",
        "df = pd.read_csv(os.path.join(output_dir, 'all_data.csv'))\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df[['FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY']].values\n",
        "y = df['Label'].values\n",
        "\n",
        "# Reshape X for LSTM input [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Split the data into 70% train, 15% validation, 15% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the Bi-LSTM Model with Attention Mechanism\n",
        "def build_bilstm_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Bi-LSTM Layer\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = layers.Attention()([x, x])\n",
        "\n",
        "    # Flatten the output of the attention layer\n",
        "    x = layers.Flatten()(attention)\n",
        "\n",
        "    # Dense Layers\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)  # Multi-class classification for 3 classes\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and Train the Model\n",
        "model = build_bilstm_attention_model((X_train.shape[1], X_train.shape[2]))\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Save model predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "df_predictions = pd.DataFrame(predictions, columns=['Healthy_Prob', 'Early_Alz_Prob', 'Alz_Prob'])\n",
        "df_predictions['True_Label'] = y_test\n",
        "df_predictions.to_csv(os.path.join(output_dir, 'test_predictions.csv'), index=False)\n",
        "\n",
        "# Generate data for three new individuals (not part of the original 400)\n",
        "new_individuals_data = []\n",
        "categories = ['healthy', 'early_alz', 'alz']\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    X_new, y_new = generate_eye_tracking_data(4, category)  # 4 samples per person\n",
        "    new_individuals_data.append((X_new, y_new, category))\n",
        "\n",
        "# Function to plot and analyze individual data\n",
        "def analyze_new_individual(X_new, y_new, category, model):\n",
        "    # Predict the individual's class\n",
        "    X_person = X_new.reshape((X_new.shape[0], 1, X_new.shape[1]))\n",
        "    person_prediction = model.predict(X_person)\n",
        "    predicted_label = np.argmax(person_prediction.mean(axis=0))\n",
        "\n",
        "    # Determine the class\n",
        "    class_labels = ['Healthy', 'Early Alzheimer\\'s', 'Alzheimer\\'s']\n",
        "    true_class = class_labels[y_new[0]]\n",
        "    predicted_class = class_labels[predicted_label]\n",
        "\n",
        "    # Generate plots\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    plt.plot(X_new[:, 0], label='Fixation Duration', marker='o')\n",
        "    plt.plot(X_new[:, 1], label='Saccade Amplitude', marker='s')\n",
        "    plt.plot(X_new[:, 2], label='Pupil Dilation', marker='D')\n",
        "    plt.plot(X_new[:, 3], label='Blink Rate', marker='^')\n",
        "    plt.title(f'New Individual ({category.capitalize()}) - Predicted: {predicted_class}')\n",
        "    plt.xlabel('Session')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print analysis report\n",
        "    print(f\"New Individual ({category.capitalize()}) Analysis Report\")\n",
        "    print(f\"True Label: {true_class}\")\n",
        "    print(f\"Predicted Label: {predicted_class}\")\n",
        "    print(f\"Prediction Probabilities: {person_prediction.mean(axis=0)}\")\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    # Interpretation based on the plot and metrics\n",
        "    print(\"Interpretation:\")\n",
        "    if predicted_class == 'Healthy':\n",
        "        print(\"The eye-tracking metrics for this individual are within normal ranges, indicating no signs of Alzheimer's.\")\n",
        "    elif predicted_class == 'Early Alzheimer\\'s':\n",
        "        print(\"The eye-tracking metrics suggest some early-stage cognitive decline, which could be indicative of early Alzheimer's.\")\n",
        "    else:  # Alzheimer's\n",
        "        print(\"The eye-tracking metrics show significant deviations from normal, consistent with Alzheimer's disease.\")\n",
        "    print(\"-----------------------------------------------------------\\n\")\n",
        "\n",
        "# Analyze and report on the three new individuals\n",
        "for X_new, y_new, category in new_individuals_data:\n",
        "    analyze_new_individual(X_new, y_new, category, model)\n"
      ],
      "metadata": {
        "id": "MbmId-GOBoh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Data Generation Function\n",
        "def generate_eye_tracking_data(num_samples, category):\n",
        "    # Generate synthetic eye-tracking metrics with different distributions based on the category\n",
        "    if category == 'healthy':\n",
        "        fixation_duration = np.random.uniform(150, 300, num_samples)  # Healthy range\n",
        "        saccade_amplitude = np.random.uniform(20, 40, num_samples)    # Healthy range\n",
        "        pupil_dilation = np.random.uniform(2, 4, num_samples)         # Healthy range\n",
        "        blink_rate = np.random.uniform(10, 15, num_samples)           # Healthy range\n",
        "    elif category == 'early_alz':\n",
        "        fixation_duration = np.random.uniform(300, 450, num_samples)  # Early-stage range\n",
        "        saccade_amplitude = np.random.uniform(10, 20, num_samples)    # Early-stage range\n",
        "        pupil_dilation = np.random.uniform(4, 6, num_samples)         # Early-stage range\n",
        "        blink_rate = np.random.uniform(15, 20, num_samples)           # Early-stage range\n",
        "    else:  # category == 'alz'\n",
        "        fixation_duration = np.random.uniform(450, 600, num_samples)  # Alzheimer's range\n",
        "        saccade_amplitude = np.random.uniform(1, 10, num_samples)     # Alzheimer's range\n",
        "        pupil_dilation = np.random.uniform(6, 8, num_samples)         # Alzheimer's range\n",
        "        blink_rate = np.random.uniform(20, 25, num_samples)           # Alzheimer's range\n",
        "\n",
        "    gaze_x = np.random.uniform(0, 1920, num_samples)              # screen resolution width\n",
        "    gaze_y = np.random.uniform(0, 1080, num_samples)              # screen resolution height\n",
        "\n",
        "    # Combine features into a single dataset\n",
        "    X = np.column_stack((fixation_duration, saccade_amplitude, pupil_dilation, blink_rate, gaze_x, gaze_y))\n",
        "\n",
        "    # Generate labels (0: Healthy, 1: Early-stage Alzheimer's, 2: Alzheimer's)\n",
        "    y = 0 if category == 'healthy' else (1 if category == 'early_alz' else 2)\n",
        "\n",
        "    return X, np.full(num_samples, y)\n",
        "\n",
        "# Function to generate and save data for multiple individuals\n",
        "def generate_and_save_data(num_individuals, num_samples_per_person, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    all_data = []\n",
        "\n",
        "    for i in range(num_individuals):\n",
        "        if i < 200:\n",
        "            category = 'healthy'\n",
        "        elif i < 300:\n",
        "            category = 'early_alz'\n",
        "        else:\n",
        "            category = 'alz'\n",
        "\n",
        "        X, y = generate_eye_tracking_data(num_samples_per_person, category)\n",
        "        person_data = np.column_stack((np.full(num_samples_per_person, i), X, y))\n",
        "        all_data.append(person_data)\n",
        "\n",
        "        # Save each person's data to a CSV file\n",
        "        df = pd.DataFrame(person_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "        df.to_csv(os.path.join(output_dir, f'person_{i}.csv'), index=False)\n",
        "\n",
        "    # Combine all data into a single dataframe\n",
        "    all_data = np.vstack(all_data)\n",
        "    df_all = pd.DataFrame(all_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "    df_all.to_csv(os.path.join(output_dir, 'all_data.csv'), index=False)\n",
        "\n",
        "# Generate and save data\n",
        "output_dir = 'eye_tracking_data'\n",
        "num_individuals = 400  # Number of individuals\n",
        "num_samples_per_person = 4  # Number of samples per individual\n",
        "\n",
        "generate_and_save_data(num_individuals, num_samples_per_person, output_dir)\n",
        "\n",
        "# Load the data from CSV\n",
        "df = pd.read_csv(os.path.join(output_dir, 'all_data.csv'))\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df[['FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY']].values\n",
        "y = df['Label'].values\n",
        "\n",
        "# Reshape X for LSTM input [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Split the data into 70% train, 15% validation, 15% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the Bi-LSTM Model with Attention Mechanism\n",
        "def build_bilstm_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Bi-LSTM Layer\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = layers.Attention()([x, x])\n",
        "\n",
        "    # Flatten the output of the attention layer\n",
        "    x = layers.Flatten()(attention)\n",
        "\n",
        "    # Dense Layers\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)  # Multi-class classification for 3 classes\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and Train the Model\n",
        "model = build_bilstm_attention_model((X_train.shape[1], X_train.shape[2]))\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Save model predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "df_predictions = pd.DataFrame(predictions, columns=['Healthy_Prob', 'Early_Alz_Prob', 'Alz_Prob'])\n",
        "df_predictions['True_Label'] = y_test\n",
        "df_predictions.to_csv(os.path.join(output_dir, 'test_predictions.csv'), index=False)\n",
        "\n",
        "# Generate data for three new individuals (not part of the original 400)\n",
        "new_individuals_data = []\n",
        "categories = ['healthy', 'early_alz', 'alz']\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    X_new, y_new = generate_eye_tracking_data(4, category)  # 4 samples per person\n",
        "    new_individuals_data.append((X_new, y_new, category))\n",
        "\n",
        "# Function to plot and analyze individual data\n",
        "def analyze_new_individual(X_new, y_new, category, model):\n",
        "    # Predict the individual's class\n",
        "    X_person = X_new.reshape((X_new.shape[0], 1, X_new.shape[1]))\n",
        "    person_prediction = model.predict(X_person)\n",
        "    predicted_label = np.argmax(person_prediction.mean(axis=0))\n",
        "\n",
        "    # Determine the class\n",
        "    class_labels = ['Healthy', 'Early Alzheimer\\'s', 'Alzheimer\\'s']\n",
        "    true_class = class_labels[y_new[0]]\n",
        "    predicted_class = class_labels[predicted_label]\n",
        "\n",
        "    # Generate line plots for each metric\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    plt.plot(X_new[:, 0], label='Fixation Duration', marker='o')\n",
        "    plt.plot(X_new[:, 1], label='Saccade Amplitude', marker='s')\n",
        "    plt.plot(X_new[:, 2], label='Pupil Dilation', marker='D')\n",
        "    plt.plot(X_new[:, 3], label='Blink Rate', marker='^')\n",
        "    plt.title(f'New Individual ({category.capitalize()}) - Predicted: {predicted_class}')\n",
        "    plt.xlabel('Session')\n",
        "    plt.ylabel('Metric Value')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Generate heatmap of the correlations between metrics\n",
        "    corr_matrix = pd.DataFrame(X_new, columns=['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate', 'Gaze X', 'Gaze Y']).corr()\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', cbar=True)\n",
        "    plt.title(f'Correlation Heatmap for {category.capitalize()} Individual')\n",
        "    plt.show()\n",
        "\n",
        "    # Generate distribution plot for each metric\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    for i, column in enumerate(['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate']):\n",
        "        sns.kdeplot(X_new[:, i], label=column, shade=True)\n",
        "    plt.title(f'Distribution of Metrics for {category.capitalize()} Individual')\n",
        "    plt.xlabel('Metric Value')\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Print analysis report\n",
        "    print(f\"New Individual ({category.capitalize()}) Analysis Report\")\n",
        "    print(f\"True Label: {true_class}\")\n",
        "    print(f\"Predicted Label: {predicted_class}\")\n",
        "    print(f\"Prediction Probabilities: {person_prediction.mean(axis=0)}\")\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    # Interpretation based on the plot and metrics\n",
        "    print(\"Interpretation:\")\n",
        "    if predicted_class == 'Healthy':\n",
        "        print(\"The eye-tracking metrics for this individual are within normal ranges, indicating no signs of Alzheimer's.\")\n",
        "    elif predicted_class == 'Early Alzheimer\\'s':\n",
        "        print(\"The eye-tracking metrics suggest some early-stage cognitive decline, which could be indicative of early Alzheimer's.\")\n",
        "    else:  # Alzheimer's\n",
        "        print(\"The eye-tracking metrics show significant deviations from normal, consistent with Alzheimer's disease.\")\n",
        "    print(\"-----------------------------------------------------------\\n\")\n",
        "\n",
        "# Analyze and report on the three new individuals\n",
        "for X_new, y_new, category in new_individuals_data:\n",
        "    analyze_new_individual(X_new, y_new, category, model)\n"
      ],
      "metadata": {
        "id": "-aJ_UEy-CR2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Data Generation Function\n",
        "def generate_eye_tracking_data(num_samples, category):\n",
        "    # Generate synthetic eye-tracking metrics with different distributions based on the category\n",
        "    if category == 'healthy':\n",
        "        fixation_duration = np.random.uniform(150, 300, num_samples)  # Healthy range\n",
        "        saccade_amplitude = np.random.uniform(20, 40, num_samples)    # Healthy range\n",
        "        pupil_dilation = np.random.uniform(2, 4, num_samples)         # Healthy range\n",
        "        blink_rate = np.random.uniform(10, 15, num_samples)           # Healthy range\n",
        "    elif category == 'early_alz':\n",
        "        fixation_duration = np.random.uniform(300, 450, num_samples)  # Early-stage range\n",
        "        saccade_amplitude = np.random.uniform(10, 20, num_samples)    # Early-stage range\n",
        "        pupil_dilation = np.random.uniform(4, 6, num_samples)         # Early-stage range\n",
        "        blink_rate = np.random.uniform(15, 20, num_samples)           # Early-stage range\n",
        "    else:  # category == 'alz'\n",
        "        fixation_duration = np.random.uniform(450, 600, num_samples)  # Alzheimer's range\n",
        "        saccade_amplitude = np.random.uniform(1, 10, num_samples)     # Alzheimer's range\n",
        "        pupil_dilation = np.random.uniform(6, 8, num_samples)         # Alzheimer's range\n",
        "        blink_rate = np.random.uniform(20, 25, num_samples)           # Alzheimer's range\n",
        "\n",
        "    gaze_x = np.random.uniform(0, 1920, num_samples)              # screen resolution width\n",
        "    gaze_y = np.random.uniform(0, 1080, num_samples)              # screen resolution height\n",
        "\n",
        "    # Combine features into a single dataset\n",
        "    X = np.column_stack((fixation_duration, saccade_amplitude, pupil_dilation, blink_rate, gaze_x, gaze_y))\n",
        "\n",
        "    # Generate labels (0: Healthy, 1: Early-stage Alzheimer's, 2: Alzheimer's)\n",
        "    y = 0 if category == 'healthy' else (1 if category == 'early_alz' else 2)\n",
        "\n",
        "    return X, np.full(num_samples, y)\n",
        "\n",
        "# Function to generate and save data for multiple individuals\n",
        "def generate_and_save_data(num_individuals, num_samples_per_person, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    all_data = []\n",
        "\n",
        "    for i in range(num_individuals):\n",
        "        if i < 200:\n",
        "            category = 'healthy'\n",
        "        elif i < 300:\n",
        "            category = 'early_alz'\n",
        "        else:\n",
        "            category = 'alz'\n",
        "\n",
        "        X, y = generate_eye_tracking_data(num_samples_per_person, category)\n",
        "        person_data = np.column_stack((np.full(num_samples_per_person, i), X, y))\n",
        "        all_data.append(person_data)\n",
        "\n",
        "        # Save each person's data to a CSV file\n",
        "        df = pd.DataFrame(person_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "        df.to_csv(os.path.join(output_dir, f'person_{i}.csv'), index=False)\n",
        "\n",
        "    # Combine all data into a single dataframe\n",
        "    all_data = np.vstack(all_data)\n",
        "    df_all = pd.DataFrame(all_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "    df_all.to_csv(os.path.join(output_dir, 'all_data.csv'), index=False)\n",
        "\n",
        "# Generate and save data\n",
        "output_dir = 'eye_tracking_data'\n",
        "num_individuals = 400  # Number of individuals\n",
        "num_samples_per_person = 4  # Number of samples per individual\n",
        "\n",
        "generate_and_save_data(num_individuals, num_samples_per_person, output_dir)\n",
        "\n",
        "# Load the data from CSV\n",
        "df = pd.read_csv(os.path.join(output_dir, 'all_data.csv'))\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df[['FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY']].values\n",
        "y = df['Label'].values\n",
        "\n",
        "# Reshape X for LSTM input [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Split the data into 70% train, 15% validation, 15% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the Bi-LSTM Model with Attention Mechanism\n",
        "def build_bilstm_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Bi-LSTM Layer\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = layers.Attention()([x, x])\n",
        "\n",
        "    # Flatten the output of the attention layer\n",
        "    x = layers.Flatten()(attention)\n",
        "\n",
        "    # Dense Layers\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)  # Multi-class classification for 3 classes\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and Train the Model\n",
        "model = build_bilstm_attention_model((X_train.shape[1], X_train.shape[2]))\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Save model predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "df_predictions = pd.DataFrame(predictions, columns=['Healthy_Prob', 'Early_Alz_Prob', 'Alz_Prob'])\n",
        "df_predictions['True_Label'] = y_test\n",
        "df_predictions.to_csv(os.path.join(output_dir, 'test_predictions.csv'), index=False)\n",
        "\n",
        "# Generate data for three new individuals (not part of the original 400)\n",
        "new_individuals_data = []\n",
        "categories = ['healthy', 'early_alz', 'alz']\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    X_new, y_new = generate_eye_tracking_data(4, category)  # 4 samples per person\n",
        "    new_individuals_data.append((X_new, y_new, category))\n",
        "\n",
        "# Function to plot and analyze individual data\n",
        "def analyze_new_individual(X_new, y_new, category, model):\n",
        "    # Predict the individual's class\n",
        "    X_person = X_new.reshape((X_new.shape[0], 1, X_new.shape[1]))\n",
        "    person_prediction = model.predict(X_person)\n",
        "    predicted_label = np.argmax(person_prediction.mean(axis=0))\n",
        "\n",
        "    # Determine the class\n",
        "    class_labels = ['Healthy', 'Early Alzheimer\\'s', 'Alzheimer\\'s']\n",
        "    true_class = class_labels[y_new[0]]\n",
        "    predicted_class = class_labels[predicted_label]\n",
        "\n",
        "    # Generate line plots for each metric\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    plt.plot(X_new[:, 0], label='Fixation Duration', marker='o', color='b', linestyle='-', linewidth=2)\n",
        "    plt.plot(X_new[:, 1], label='Saccade Amplitude', marker='s', color='g', linestyle='--', linewidth=2)\n",
        "    plt.plot(X_new[:, 2], label='Pupil Dilation', marker='D', color='r', linestyle='-.', linewidth=2)\n",
        "    plt.plot(X_new[:, 3], label='Blink Rate', marker='^', color='m', linestyle=':', linewidth=2)\n",
        "    plt.title(f'New Individual ({category.capitalize()}) - Predicted: {predicted_class}', fontsize=16)\n",
        "    plt.xlabel('Session', fontsize=14)\n",
        "    plt.ylabel('Metric Value', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Generate heatmap of the correlations between metrics\n",
        "    corr_matrix = pd.DataFrame(X_new, columns=['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate', 'Gaze X', 'Gaze Y']).corr()\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', cbar=True, annot_kws={\"size\": 12})\n",
        "    plt.title(f'Correlation Heatmap for {category.capitalize()} Individual', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "    # Generate distribution plot for each metric\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    for i, column in enumerate(['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate']):\n",
        "        sns.kdeplot(X_new[:, i], label=column, shade=True, linewidth=2)\n",
        "    plt.title(f'Distribution of Metrics for {category.capitalize()} Individual', fontsize=16)\n",
        "    plt.xlabel('Metric Value', fontsize=14)\n",
        "    plt.ylabel('Density', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Print analysis report\n",
        "    print(f\"New Individual ({category.capitalize()}) Analysis Report\")\n",
        "    print(f\"True Label: {true_class}\")\n",
        "    print(f\"Predicted Label: {predicted_class}\")\n",
        "    print(f\"Prediction Probabilities: {person_prediction.mean(axis=0)}\")\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    # Interpretation based on the plot and metrics\n",
        "    print(\"Interpretation:\")\n",
        "    if predicted_class == 'Healthy':\n",
        "        print(\"The eye-tracking metrics for this individual are within normal ranges, indicating no signs of Alzheimer's. The person likely does not have Alzheimer's disease based on the observed data.\")\n",
        "    elif predicted_class == 'Early Alzheimer\\'s':\n",
        "        print(\"The eye-tracking metrics suggest some early-stage cognitive decline. These patterns are consistent with early Alzheimer's disease, indicating that the person might be in the early stages of the condition.\")\n",
        "    else:  # Alzheimer's\n",
        "        print(\"The eye-tracking metrics show significant deviations from normal ranges, with patterns consistent with Alzheimer's disease. The person likely has Alzheimer's disease based on the observed data.\")\n",
        "    print(\"-----------------------------------------------------------\\n\")\n",
        "\n",
        "# Analyze and report on the three new individuals\n",
        "for X_new, y_new, category in new_individuals_data:\n",
        "    analyze_new_individual(X_new, y_new, category, model)\n"
      ],
      "metadata": {
        "id": "qqKk5e3UDFfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Data Generation Function\n",
        "def generate_eye_tracking_data(num_samples, category):\n",
        "    # Generate synthetic eye-tracking metrics with different distributions based on the category\n",
        "    if category == 'healthy':\n",
        "        fixation_duration = np.random.uniform(150, 300, num_samples)  # Healthy range\n",
        "        saccade_amplitude = np.random.uniform(20, 40, num_samples)    # Healthy range\n",
        "        pupil_dilation = np.random.uniform(2, 4, num_samples)         # Healthy range\n",
        "        blink_rate = np.random.uniform(10, 15, num_samples)           # Healthy range\n",
        "    elif category == 'early_alz':\n",
        "        fixation_duration = np.random.uniform(300, 450, num_samples)  # Early-stage range\n",
        "        saccade_amplitude = np.random.uniform(10, 20, num_samples)    # Early-stage range\n",
        "        pupil_dilation = np.random.uniform(4, 6, num_samples)         # Early-stage range\n",
        "        blink_rate = np.random.uniform(15, 20, num_samples)           # Early-stage range\n",
        "    else:  # category == 'alz'\n",
        "        fixation_duration = np.random.uniform(450, 600, num_samples)  # Alzheimer's range\n",
        "        saccade_amplitude = np.random.uniform(1, 10, num_samples)     # Alzheimer's range\n",
        "        pupil_dilation = np.random.uniform(6, 8, num_samples)         # Alzheimer's range\n",
        "        blink_rate = np.random.uniform(20, 25, num_samples)           # Alzheimer's range\n",
        "\n",
        "    gaze_x = np.random.uniform(0, 1920, num_samples)              # screen resolution width\n",
        "    gaze_y = np.random.uniform(0, 1080, num_samples)              # screen resolution height\n",
        "\n",
        "    # Combine features into a single dataset\n",
        "    X = np.column_stack((fixation_duration, saccade_amplitude, pupil_dilation, blink_rate, gaze_x, gaze_y))\n",
        "\n",
        "    # Generate labels (0: Healthy, 1: Early-stage Alzheimer's, 2: Alzheimer's)\n",
        "    y = 0 if category == 'healthy' else (1 if category == 'early_alz' else 2)\n",
        "\n",
        "    return X, np.full(num_samples, y)\n",
        "\n",
        "# Function to generate and save data for multiple individuals\n",
        "def generate_and_save_data(num_individuals, num_samples_per_person, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    all_data = []\n",
        "\n",
        "    for i in range(num_individuals):\n",
        "        if i < 200:\n",
        "            category = 'healthy'\n",
        "        elif i < 300:\n",
        "            category = 'early_alz'\n",
        "        else:\n",
        "            category = 'alz'\n",
        "\n",
        "        X, y = generate_eye_tracking_data(num_samples_per_person, category)\n",
        "        person_data = np.column_stack((np.full(num_samples_per_person, i), X, y))\n",
        "        all_data.append(person_data)\n",
        "\n",
        "        # Save each person's data to a CSV file\n",
        "        df = pd.DataFrame(person_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "        df.to_csv(os.path.join(output_dir, f'person_{i}.csv'), index=False)\n",
        "\n",
        "    # Combine all data into a single dataframe\n",
        "    all_data = np.vstack(all_data)\n",
        "    df_all = pd.DataFrame(all_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "    df_all.to_csv(os.path.join(output_dir, 'all_data.csv'), index=False)\n",
        "\n",
        "# Generate and save data\n",
        "output_dir = 'eye_tracking_data'\n",
        "num_individuals = 400  # Number of individuals\n",
        "num_samples_per_person = 4  # Number of samples per individual\n",
        "\n",
        "generate_and_save_data(num_individuals, num_samples_per_person, output_dir)\n",
        "\n",
        "# Load the data from CSV\n",
        "df = pd.read_csv(os.path.join(output_dir, 'all_data.csv'))\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df[['FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY']].values\n",
        "y = df['Label'].values\n",
        "\n",
        "# Reshape X for LSTM input [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Split the data into 70% train, 15% validation, 15% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the Bi-LSTM Model with Attention Mechanism\n",
        "def build_bilstm_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Bi-LSTM Layer\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = layers.Attention()([x, x])\n",
        "\n",
        "    # Flatten the output of the attention layer\n",
        "    x = layers.Flatten()(attention)\n",
        "\n",
        "    # Dense Layers\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)  # Multi-class classification for 3 classes\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and Train the Model\n",
        "model = build_bilstm_attention_model((X_train.shape[1], X_train.shape[2]))\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Save model predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "df_predictions = pd.DataFrame(predictions, columns=['Healthy_Prob', 'Early_Alz_Prob', 'Alz_Prob'])\n",
        "df_predictions['True_Label'] = y_test\n",
        "df_predictions.to_csv(os.path.join(output_dir, 'test_predictions.csv'), index=False)\n",
        "\n",
        "# Generate data for three new individuals (not part of the original 400)\n",
        "new_individuals_data = []\n",
        "categories = ['healthy', 'early_alz', 'alz']\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    X_new, y_new = generate_eye_tracking_data(4, category)  # 4 samples per person\n",
        "    new_individuals_data.append((X_new, y_new, category))\n",
        "\n",
        "# Function to plot and analyze individual data\n",
        "def analyze_new_individual(X_new, y_new, category, model):\n",
        "    # Predict the individual's class\n",
        "    X_person = X_new.reshape((X_new.shape[0], 1, X_new.shape[1]))\n",
        "    person_prediction = model.predict(X_person)\n",
        "    predicted_label = np.argmax(person_prediction.mean(axis=0))\n",
        "\n",
        "    # Determine the class\n",
        "    class_labels = ['Healthy', 'Early Alzheimer\\'s', 'Alzheimer\\'s']\n",
        "    true_class = class_labels[y_new[0]]\n",
        "    predicted_class = class_labels[predicted_label]\n",
        "\n",
        "    # Generate line plots for each metric\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    plt.plot(X_new[:, 0], label='Fixation Duration', marker='o', color='b', linestyle='-', linewidth=2)\n",
        "    plt.plot(X_new[:, 1], label='Saccade Amplitude', marker='s', color='g', linestyle='--', linewidth=2)\n",
        "    plt.plot(X_new[:, 2], label='Pupil Dilation', marker='D', color='r', linestyle='-.', linewidth=2)\n",
        "    plt.plot(X_new[:, 3], label='Blink Rate', marker='^', color='m', linestyle=':', linewidth=2)\n",
        "    plt.title(f'New Individual ({category.capitalize()}) - Predicted: {predicted_class}', fontsize=16)\n",
        "    plt.xlabel('Session', fontsize=14)\n",
        "    plt.ylabel('Metric Value', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Generate heatmap of the correlations between metrics\n",
        "    corr_matrix = pd.DataFrame(X_new, columns=['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate', 'Gaze X', 'Gaze Y']).corr()\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', cbar=True, annot_kws={\"size\": 12})\n",
        "    plt.title(f'Correlation Heatmap for {category.capitalize()} Individual', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "    # Generate distribution plot for each metric\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    for i, column in enumerate(['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate']):\n",
        "        sns.kdeplot(X_new[:, i], label=column, fill=True, linewidth=2)\n",
        "    plt.title(f'Distribution of Metrics for {category.capitalize()} Individual', fontsize=16)\n",
        "    plt.xlabel('Metric Value', fontsize=14)\n",
        "    plt.ylabel('Density', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Print analysis report\n",
        "    print(f\"New Individual ({category.capitalize()}) Analysis Report\")\n",
        "    print(f\"True Label: {true_class}\")\n",
        "    print(f\"Predicted Label: {predicted_class}\")\n",
        "    print(f\"Prediction Probabilities: {person_prediction.mean(axis=0)}\")\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    # Interpretation based on the plot and metrics\n",
        "    print(\"Interpretation:\")\n",
        "    if predicted_class == 'Healthy':\n",
        "        print(\"The eye-tracking metrics for this individual are within normal ranges, indicating no signs of Alzheimer's. The person likely does not have Alzheimer's disease based on the observed data.\")\n",
        "    elif predicted_class == 'Early Alzheimer\\'s':\n",
        "        print(\"The eye-tracking metrics suggest some early-stage cognitive decline. These patterns are consistent with early Alzheimer's disease, indicating that the person might be in the early stages of the condition.\")\n",
        "    else:  # Alzheimer's\n",
        "        print(\"The eye-tracking metrics show significant deviations from normal ranges, with patterns consistent with Alzheimer's disease. The person likely has Alzheimer's disease based on the observed data.\")\n",
        "    print(\"-----------------------------------------------------------\\n\")\n",
        "\n",
        "# Analyze and report on the three new individuals\n",
        "for X_new, y_new, category in new_individuals_data:\n",
        "    analyze_new_individual(X_new, y_new, category, model)\n"
      ],
      "metadata": {
        "id": "-G5oPKhKDdzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from math import pi\n",
        "import os\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Data Generation Function\n",
        "def generate_eye_tracking_data(num_samples, category):\n",
        "    # Generate synthetic eye-tracking metrics with different distributions based on the category\n",
        "    if category == 'healthy':\n",
        "        fixation_duration = np.random.uniform(150, 300, num_samples)  # Healthy range\n",
        "        saccade_amplitude = np.random.uniform(20, 40, num_samples)    # Healthy range\n",
        "        pupil_dilation = np.random.uniform(2, 4, num_samples)         # Healthy range\n",
        "        blink_rate = np.random.uniform(10, 15, num_samples)           # Healthy range\n",
        "    elif category == 'early_alz':\n",
        "        fixation_duration = np.random.uniform(300, 450, num_samples)  # Early-stage range\n",
        "        saccade_amplitude = np.random.uniform(10, 20, num_samples)    # Early-stage range\n",
        "        pupil_dilation = np.random.uniform(4, 6, num_samples)         # Early-stage range\n",
        "        blink_rate = np.random.uniform(15, 20, num_samples)           # Early-stage range\n",
        "    else:  # category == 'alz'\n",
        "        fixation_duration = np.random.uniform(450, 600, num_samples)  # Alzheimer's range\n",
        "        saccade_amplitude = np.random.uniform(1, 10, num_samples)     # Alzheimer's range\n",
        "        pupil_dilation = np.random.uniform(6, 8, num_samples)         # Alzheimer's range\n",
        "        blink_rate = np.random.uniform(20, 25, num_samples)           # Alzheimer's range\n",
        "\n",
        "    gaze_x = np.random.uniform(0, 1920, num_samples)              # screen resolution width\n",
        "    gaze_y = np.random.uniform(0, 1080, num_samples)              # screen resolution height\n",
        "\n",
        "    # Combine features into a single dataset\n",
        "    X = np.column_stack((fixation_duration, saccade_amplitude, pupil_dilation, blink_rate, gaze_x, gaze_y))\n",
        "\n",
        "    # Generate labels (0: Healthy, 1: Early-stage Alzheimer's, 2: Alzheimer's)\n",
        "    y = 0 if category == 'healthy' else (1 if category == 'early_alz' else 2)\n",
        "\n",
        "    return X, np.full(num_samples, y)\n",
        "\n",
        "# Function to generate and save data for multiple individuals\n",
        "def generate_and_save_data(num_individuals, num_samples_per_person, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    all_data = []\n",
        "\n",
        "    for i in range(num_individuals):\n",
        "        if i < 200:\n",
        "            category = 'healthy'\n",
        "        elif i < 300:\n",
        "            category = 'early_alz'\n",
        "        else:\n",
        "            category = 'alz'\n",
        "\n",
        "        X, y = generate_eye_tracking_data(num_samples_per_person, category)\n",
        "        person_data = np.column_stack((np.full(num_samples_per_person, i), X, y))\n",
        "        all_data.append(person_data)\n",
        "\n",
        "        # Save each person's data to a CSV file\n",
        "        df = pd.DataFrame(person_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "        df.to_csv(os.path.join(output_dir, f'person_{i}.csv'), index=False)\n",
        "\n",
        "    # Combine all data into a single dataframe\n",
        "    all_data = np.vstack(all_data)\n",
        "    df_all = pd.DataFrame(all_data, columns=['PersonID', 'FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY', 'Label'])\n",
        "    df_all.to_csv(os.path.join(output_dir, 'all_data.csv'), index=False)\n",
        "\n",
        "# Generate and save data\n",
        "output_dir = 'eye_tracking_data'\n",
        "num_individuals = 400  # Number of individuals\n",
        "num_samples_per_person = 4  # Number of samples per individual\n",
        "\n",
        "generate_and_save_data(num_individuals, num_samples_per_person, output_dir)\n",
        "\n",
        "# Load the data from CSV\n",
        "df = pd.read_csv(os.path.join(output_dir, 'all_data.csv'))\n",
        "\n",
        "# Split the data into features and labels\n",
        "X = df[['FixationDuration', 'SaccadeAmplitude', 'PupilDilation', 'BlinkRate', 'GazeX', 'GazeY']].values\n",
        "y = df['Label'].values\n",
        "\n",
        "# Reshape X for LSTM input [samples, timesteps, features]\n",
        "X = X.reshape((X.shape[0], 1, X.shape[1]))\n",
        "\n",
        "# Split the data into 70% train, 15% validation, 15% test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Build the Bi-LSTM Model with Attention Mechanism\n",
        "def build_bilstm_attention_model(input_shape):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Bi-LSTM Layer\n",
        "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True))(inputs)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = layers.Attention()([x, x])\n",
        "\n",
        "    # Flatten the output of the attention layer\n",
        "    x = layers.Flatten()(attention)\n",
        "\n",
        "    # Dense Layers\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "\n",
        "    # Output Layer\n",
        "    outputs = layers.Dense(3, activation='softmax')(x)  # Multi-class classification for 3 classes\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Build and Train the Model\n",
        "model = build_bilstm_attention_model((X_train.shape[1], X_train.shape[2]))\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=50,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
        "\n",
        "# Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "# Save model predictions on the test set\n",
        "predictions = model.predict(X_test)\n",
        "df_predictions = pd.DataFrame(predictions, columns=['Healthy_Prob', 'Early_Alz_Prob', 'Alz_Prob'])\n",
        "df_predictions['True_Label'] = y_test\n",
        "df_predictions.to_csv(os.path.join(output_dir, 'test_predictions.csv'), index=False)\n",
        "\n",
        "# Generate data for three new individuals (not part of the original 400)\n",
        "new_individuals_data = []\n",
        "categories = ['healthy', 'early_alz', 'alz']\n",
        "\n",
        "for i, category in enumerate(categories):\n",
        "    X_new, y_new = generate_eye_tracking_data(4, category)  # 4 samples per person\n",
        "    new_individuals_data.append((X_new, y_new, category))\n",
        "\n",
        "# Function to plot and analyze individual data\n",
        "def analyze_new_individual(X_new, y_new, category, model):\n",
        "    # Predict the individual's class\n",
        "    X_person = X_new.reshape((X_new.shape[0], 1, X_new.shape[1]))\n",
        "    person_prediction = model.predict(X_person)\n",
        "    predicted_label = np.argmax(person_prediction.mean(axis=0))\n",
        "\n",
        "    # Determine the class\n",
        "    class_labels = ['Healthy', 'Early Alzheimer\\'s', 'Alzheimer\\'s']\n",
        "    true_class = class_labels[y_new[0]]\n",
        "    predicted_class = class_labels[predicted_label]\n",
        "\n",
        "    # Generate line plots for each metric\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    plt.plot(X_new[:, 0], label='Fixation Duration', marker='o', color='b', linestyle='-', linewidth=2)\n",
        "    plt.plot(X_new[:, 1], label='Saccade Amplitude', marker='s', color='g', linestyle='--', linewidth=2)\n",
        "    plt.plot(X_new[:, 2], label='Pupil Dilation', marker='D', color='r', linestyle='-.', linewidth=2)\n",
        "    plt.plot(X_new[:, 3], label='Blink Rate', marker='^', color='m', linestyle=':', linewidth=2)\n",
        "    plt.title(f'New Individual ({category.capitalize()}) - Predicted: {predicted_class}', fontsize=16)\n",
        "    plt.xlabel('Session', fontsize=14)\n",
        "    plt.ylabel('Metric Value', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Scatter plot of Pupil Dilation vs Fixation Duration\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x=X_new[:, 0], y=X_new[:, 2], hue=['Session 1', 'Session 2', 'Session 3', 'Session 4'], palette='coolwarm', s=100)\n",
        "    plt.title(f'Pupil Dilation vs Fixation Duration for {category.capitalize()} Individual', fontsize=16)\n",
        "    plt.xlabel('Fixation Duration (ms)', fontsize=14)\n",
        "    plt.ylabel('Pupil Dilation (mm)', fontsize=14)\n",
        "    plt.legend(title='Session', fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Time-Series Analysis Plot for each metric\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    for i, metric in enumerate(['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate']):\n",
        "        plt.plot(X_new[:, i], marker='o', label=metric, linewidth=2)\n",
        "    plt.title(f'Time-Series Analysis for {category.capitalize()} Individual', fontsize=16)\n",
        "    plt.xlabel('Session', fontsize=14)\n",
        "    plt.ylabel('Metric Value', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Box Plot for each metric\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    df_box = pd.DataFrame(X_new, columns=['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate', 'Gaze X', 'Gaze Y'])\n",
        "    sns.boxplot(data=df_box[['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate']])\n",
        "    plt.title(f'Box Plot of Metrics for {category.capitalize()} Individual', fontsize=16)\n",
        "    plt.xlabel('Metric', fontsize=14)\n",
        "    plt.ylabel('Value', fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Radar Chart for metrics\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    categories = ['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate']\n",
        "    values = X_new.mean(axis=0)[:4].tolist()\n",
        "    values += values[:1]  # Close the radar chart loop\n",
        "\n",
        "    angles = [n / float(len(categories)) * 2 * pi for n in range(len(categories))]\n",
        "    angles += angles[:1]\n",
        "\n",
        "    ax = plt.subplot(111, polar=True)\n",
        "    plt.xticks(angles[:-1], categories, color='grey', size=12)\n",
        "    ax.plot(angles, values, linewidth=2, linestyle='solid')\n",
        "    ax.fill(angles, values, 'b', alpha=0.3)\n",
        "    plt.title(f'Radar Chart for {category.capitalize()} Individual', size=16)\n",
        "    plt.show()\n",
        "\n",
        "    # Generate heatmap of the correlations between metrics\n",
        "    corr_matrix = pd.DataFrame(X_new, columns=['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate', 'Gaze X', 'Gaze Y']).corr()\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', cbar=True, annot_kws={\"size\": 12})\n",
        "    plt.title(f'Correlation Heatmap for {category.capitalize()} Individual', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "    # Generate distribution plot for each metric\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    for i, column in enumerate(['Fixation Duration', 'Saccade Amplitude', 'Pupil Dilation', 'Blink Rate']):\n",
        "        sns.kdeplot(X_new[:, i], label=column, fill=True, linewidth=2)\n",
        "    plt.title(f'Distribution of Metrics for {category.capitalize()} Individual', fontsize=16)\n",
        "    plt.xlabel('Metric Value', fontsize=14)\n",
        "    plt.ylabel('Density', fontsize=14)\n",
        "    plt.legend(fontsize=12)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Print analysis report\n",
        "    print(f\"New Individual ({category.capitalize()}) Analysis Report\")\n",
        "    print(f\"True Label: {true_class}\")\n",
        "    print(f\"Predicted Label: {predicted_class}\")\n",
        "    print(f\"Prediction Probabilities: {person_prediction.mean(axis=0)}\")\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    # Interpretation based on the plot and metrics\n",
        "    print(\"Interpretation:\")\n",
        "    if predicted_class == 'Healthy':\n",
        "        print(\"The eye-tracking metrics for this individual are within normal ranges, indicating no signs of Alzheimer's. The person likely does not have Alzheimer's disease based on the observed data.\")\n",
        "    elif predicted_class == 'Early Alzheimer\\'s':\n",
        "        print(\"The eye-tracking metrics suggest some early-stage cognitive decline. These patterns are consistent with early Alzheimer's disease, indicating that the person might be in the early stages of the condition.\")\n",
        "    else:  # Alzheimer's\n",
        "        print(\"The eye-tracking metrics show significant deviations from normal ranges, with patterns consistent with Alzheimer's disease. The person likely has Alzheimer's disease based on the observed data.\")\n",
        "    print(\"-----------------------------------------------------------\\n\")\n",
        "\n",
        "# Analyze and report on the three new individuals\n",
        "for X_new, y_new, category in new_individuals_data:\n",
        "    analyze_new_individual(X_new, y_new, category, model)\n"
      ],
      "metadata": {
        "id": "kWkBeLc_EhvC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}